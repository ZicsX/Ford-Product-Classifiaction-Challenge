{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "train=pd.read_csv('train0.csv')\n",
    "test=pd.read_csv('test0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove spaces from the data\n",
    "train=train.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "test=test.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values with np.nan\n",
    "train=train.replace(\"nan\",np.nan)\n",
    "train=train.replace(\"?\",np.nan)\n",
    "train=train.replace(\"None\",np.nan)\n",
    "\n",
    "test=test.replace(\"nan\",np.nan)\n",
    "test=test.replace(\"?\",np.nan)\n",
    "test=test.replace(\"None\",np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 'Revenue', 'Net_Valuation', 'Share_Price' to numeric values\n",
    "train['Revenue']=pd.to_numeric(train['Revenue'],errors='coerce')\n",
    "train['Net_Valuation']=pd.to_numeric(train['Net_Valuation'],errors='coerce')\n",
    "train['Share_Price']=pd.to_numeric(train['Share_Price'],errors='coerce')\n",
    "\n",
    "test['Revenue']=pd.to_numeric(test['Revenue'],errors='coerce')\n",
    "test['Net_Valuation']=pd.to_numeric(test['Net_Valuation'],errors='coerce')\n",
    "test['Share_Price']=pd.to_numeric(test['Share_Price'],errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['File_Name', 'Location', 'Sector', 'Employees', 'Revenue',\n",
       "       'Net_Valuation', 'Share_Price', 'Company_Background', 'Product'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AI', 'Truck', 'Medical devices', 'antivirus-security', 'Hydro',\n",
       "       'Organicfood', 'charcoal', 'Kids toys', 'Fuel', 'Gaming hardware',\n",
       "       'Bike', 'allopathy', 'Solar'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Product.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # drop File_Name\n",
    "# train.drop('File_Name',axis=1,inplace=True)\n",
    "\n",
    "# File_Name = test['File_Name']\n",
    "# test.drop('File_Name',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique values in Location\n",
    "train.Location.append(test.Location).unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Public_sector', nan, 'Private_sector'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique values in Sector\n",
    "train.Sector.append(test.Sector).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace underscore from Sector with space\n",
    "train.Sector=train.Sector.replace('Public_sector','Public sector')\n",
    "test.Sector=test.Sector.replace('Public_sector','Public sector')\n",
    "\n",
    "train.Sector=train.Sector.replace('Private_sector','Private sector')\n",
    "test.Sector=test.Sector.replace('Private_sector','Private sector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values in Company_Background with empty string\n",
    "train.Company_Background.fillna('',inplace=True)\n",
    "test.Company_Background.fillna('',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate Company_Background with all other columns\n",
    "\n",
    "# location\n",
    "idx = train.Location[train.Location.notnull()].index\n",
    "train.loc[idx,'Company_Background'] = train.loc[idx,'Company_Background'] + ' This Company is based out of ' + train.loc[idx,'Location'] + '.'\n",
    "# Sector\n",
    "idx = train.Sector[train.Sector.notnull()].index\n",
    "train.loc[idx,'Company_Background'] = train.loc[idx,'Company_Background'] + ' This Company is in the ' + train.loc[idx,'Sector'] + '.'\n",
    "# Employees\n",
    "idx = train.Employees[train.Employees.notnull()].index\n",
    "train.Employees = train.Employees.fillna('0')\n",
    "train['Employees']=train['Employees'].astype(float).astype(int)\n",
    "train.loc[idx,'Company_Background'] = train.loc[idx,'Company_Background'] + ' This Company has ' + train.loc[idx,'Employees'].astype(str) + '.' + ' employees.'\n",
    "# Revenue\n",
    "idx = train.Revenue[train.Revenue.notnull()].index\n",
    "train.loc[idx,'Company_Background'] = train.loc[idx,'Company_Background'] + ' This Company has a revenue of ' + train.loc[idx,'Revenue'].round(1).astype(str) + ' Milions.'\n",
    "# Net_Valuation\n",
    "idx = train.Net_Valuation[train.Net_Valuation.notnull()].index\n",
    "train.loc[idx,'Company_Background'] = train.loc[idx,'Company_Background'] + ' This Company has a net valuation of ' + train.loc[idx,'Net_Valuation'].round(1).astype(str) + '.'\n",
    "# Share_Price\n",
    "idx = train.Share_Price[train.Share_Price.notnull()].index\n",
    "train.loc[idx,'Company_Background'] = train.loc[idx,'Company_Background'] + ' This Company has a share price of ' + train.loc[idx,'Share_Price'].round(1).astype(str) + '.'\n",
    "\n",
    "# Test data\n",
    "\n",
    "# location\n",
    "idx = test.Location[test.Location.notnull()].index\n",
    "test.loc[idx,'Company_Background'] = test.loc[idx,'Company_Background'] + ' This Company is based out of ' + test.loc[idx,'Location'] + '.'\n",
    "# Sector\n",
    "idx = test.Sector[test.Sector.notnull()].index\n",
    "test.loc[idx,'Company_Background'] = test.loc[idx,'Company_Background'] + ' This Company is in the ' + test.loc[idx,'Sector'] + '.'\n",
    "# Employees\n",
    "idx = test.Employees[test.Employees.notnull()].index\n",
    "test.Employees = test.Employees.fillna('0')\n",
    "test['Employees']=test['Employees'].astype(float).astype(int)\n",
    "test.loc[idx,'Company_Background'] = test.loc[idx,'Company_Background'] + ' This Company has ' + test.loc[idx,'Employees'].astype(str) + ' employees.'\n",
    "# Revenue\n",
    "idx = test.Revenue[test.Revenue.notnull()].index\n",
    "test.loc[idx,'Company_Background'] = test.loc[idx,'Company_Background'] + ' This Company has a revenue of ' + test.loc[idx,'Revenue'].round(1).astype(str) + ' Milions.'\n",
    "# Net_Valuation\n",
    "idx = test.Net_Valuation[test.Net_Valuation.notnull()].index\n",
    "test.loc[idx,'Company_Background'] = test.loc[idx,'Company_Background'] + ' This Company has a net valuation of ' + test.loc[idx,'Net_Valuation'].round(1).astype(str) + '.'\n",
    "# Share_Price\n",
    "idx = test.Share_Price[test.Share_Price.notnull()].index\n",
    "test.loc[idx,'Company_Background'] = test.loc[idx,'Company_Background'] + ' This Company has a share price of ' + test.loc[idx,'Share_Price'].round(1).astype(str) + '.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 9)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.Company_Background==''].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary columns from train and test\n",
    "train = train.drop(['Location','Sector','Employees','Revenue','Net_Valuation','Share_Price'],axis=1)\n",
    "test = test.drop(['Location','Sector','Employees','Revenue','Net_Valuation','Share_Price'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.Company_Background[0] = 'This Company has a revenue of 139.3 Milions. This Company has a net valuation of 27869.4. This Company has a share price of 214428.8.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save preprocessed data\n",
    "train.to_csv('train1.csv',index=False)\n",
    "test.to_csv('test1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load preprocessed data\n",
    "train = pd.read_csv('train1.csv')\n",
    "test = pd.read_csv('test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Company_Background</th>\n",
       "      <th>Product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PROJ0x130f.html</td>\n",
       "      <td>More complex computations may involve many ope...</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PROJ0x61c1.html</td>\n",
       "      <td>It would have had two super heavy variants: on...</td>\n",
       "      <td>Truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PROJ0x520d.html</td>\n",
       "      <td>The standard ISO 26262, is considered as one o...</td>\n",
       "      <td>Truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PROJ0x1d31.html</td>\n",
       "      <td>Diana Zuckerman published in the peer-reviewed...</td>\n",
       "      <td>Medical devices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PROJ0x77de.html</td>\n",
       "      <td>From this perspective, security and insecurity...</td>\n",
       "      <td>antivirus-security</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         File_Name                                 Company_Background  \\\n",
       "0  PROJ0x130f.html  More complex computations may involve many ope...   \n",
       "1  PROJ0x61c1.html  It would have had two super heavy variants: on...   \n",
       "2  PROJ0x520d.html  The standard ISO 26262, is considered as one o...   \n",
       "3  PROJ0x1d31.html  Diana Zuckerman published in the peer-reviewed...   \n",
       "4  PROJ0x77de.html  From this perspective, security and insecurity...   \n",
       "\n",
       "              Product  \n",
       "0                  AI  \n",
       "1               Truck  \n",
       "2               Truck  \n",
       "3     Medical devices  \n",
       "4  antivirus-security  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Company_Background</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PROJ0x1016.html</td>\n",
       "      <td>This Company has a revenue of 139.3 Milions. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PROJ0x1024.html</td>\n",
       "      <td>We shall call it information technology (IT). ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PROJ0x102f.html</td>\n",
       "      <td>MAN SE holds a 17.All of the above light comme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PROJ0x1033.html</td>\n",
       "      <td>It is not only the \"cause of knowledge and tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PROJ0x1034.html</td>\n",
       "      <td>Although industry restructuring proceeded, the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         File_Name                                 Company_Background\n",
       "0  PROJ0x1016.html  This Company has a revenue of 139.3 Milions. T...\n",
       "1  PROJ0x1024.html  We shall call it information technology (IT). ...\n",
       "2  PROJ0x102f.html  MAN SE holds a 17.All of the above light comme...\n",
       "3  PROJ0x1033.html  It is not only the \"cause of knowledge and tru...\n",
       "4  PROJ0x1034.html  Although industry restructuring proceeded, the..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train.head())\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop File_Name\n",
    "train.drop('File_Name',axis=1,inplace=True)\n",
    "\n",
    "File_Name = test['File_Name']\n",
    "test.drop('File_Name',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change categorical data to numerical data\n",
    "train.replace({'Product' : { 'AI' : 0, 'Truck' : 1, 'Medical devices' : 2, 'antivirus-security' : 3, 'Hydro' : 4,\n",
    "         'Organicfood' : 5, 'charcoal' : 6, 'Kids toys' : 7, 'Fuel' : 8, 'Gaming hardware' : 9,\n",
    "            'Bike' : 10, 'allopathy' : 11, 'Solar' : 12}},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import transformers and tokenizers\n",
    "from tqdm.auto import tqdm\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cd30d86e40b4e9f9943c0c750ca458d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9d5d3ad997d420e94fe2ed5b934d042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero array of shape (len(train),256)\n",
    "X_input_ids = np.zeros((len(train), 256))\n",
    "X_attn_masks = np.zeros((len(train), 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(train, ids, masks, tokenizer):\n",
    "    for i, text in tqdm(enumerate(train['Company_Background'])):\n",
    "        tokenized_text = tokenizer.encode_plus(\n",
    "            text,\n",
    "            max_length=256, \n",
    "            truncation=True, \n",
    "            padding='max_length', \n",
    "            add_special_tokens=True,\n",
    "            return_tensors='tf'\n",
    "        )\n",
    "        ids[i, :] = tokenized_text.input_ids\n",
    "        masks[i, :] = tokenized_text.attention_mask\n",
    "    return ids, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5f44e232223414d8078764402a888d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate input ids and attention masks\n",
    "X_input_ids, X_attn_masks = generate_training_data(train, X_input_ids, X_attn_masks, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13452, 13)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a zeor array for label \n",
    "labels = np.zeros((len(train), 13))\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding of labels\n",
    "labels[np.arange(len(train)), train['Product'].values] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a data pipeline using tensorflow dataset utility\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_input_ids, X_attn_masks, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasetMapFunction(input_ids, attn_masks, labels):\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attn_masks\n",
    "    }, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataset with maping input ids, attention masks and labels\n",
    "dataset = dataset.map(datasetMapFunction)\n",
    "\n",
    "# split dataset into train and validation\n",
    "dataset = dataset.shuffle(1000).batch(16, drop_remainder=True)\n",
    "\n",
    "p = 0.8\n",
    "train_size = int((len(train)//16)*p)\n",
    "\n",
    "train_dataset = dataset.take(train_size)\n",
    "val_dataset = dataset.skip(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import BERt model\n",
    "from transformers import TFBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada83e2aa2064e28b2d2ac274a629df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/527M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# load bert base model\n",
    "model = TFBertModel.from_pretrained('bert-base-cased') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " bert (TFBertMainLayer)         TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 256,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " intermediate_layer (Dense)     (None, 512)          393728      ['bert[0][1]']                   \n",
      "                                                                                                  \n",
      " output_layer (Dense)           (None, 13)           6669        ['intermediate_layer[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 108,710,669\n",
      "Trainable params: 108,710,669\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create a model\n",
    "input_ids = tf.keras.layers.Input(shape=(256,), name='input_ids', dtype='int32')\n",
    "attn_masks = tf.keras.layers.Input(shape=(256,), name='attention_mask', dtype='int32')\n",
    "\n",
    "bert_embds = model.bert(input_ids, attention_mask=attn_masks)[1]\n",
    "intermediate_layer = tf.keras.layers.Dense(512, activation='relu', name='intermediate_layer')(bert_embds)\n",
    "output_layer = tf.keras.layers.Dense(13, activation='softmax', name='output_layer')(intermediate_layer)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_ids, attn_masks], outputs=output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model with optimizer, loss and metrics\n",
    "optim = tf.keras.optimizers.Adam(learning_rate=1e-5, decay=1e-6)\n",
    "loss_func = tf.keras.losses.CategoricalCrossentropy()\n",
    "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
    "\n",
    "model.compile(optimizer=optim, loss=loss_func, metrics=[acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "history = model.fit( train_dataset, validation_data=val_dataset, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model weights\n",
    "model.save('product_class_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model weights\n",
    "model = tf.keras.models.load_model('product_class_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare test data\n",
    "X_input_ids = np.zeros((len(test), 256))\n",
    "X_attn_masks = np.zeros((len(test), 256))\n",
    "\n",
    "X_input_ids, X_attn_masks = generate_training_data(test, X_input_ids, X_attn_masks, tokenizer)\n",
    "\n",
    "# create a data pipeline for test data\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_input_ids, X_attn_masks))\n",
    "\n",
    "def datasetMapFunction(input_ids, attn_masks):\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attn_masks\n",
    "    }\n",
    "\n",
    "# create dataset with maping input ids and attention masks\n",
    "test_dataset = test_dataset.map(datasetMapFunction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test data\n",
    "pred = model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot to categorical\n",
    "classes = ['AI', 'Truck', 'Medical devices', 'antivirus-security', 'Hydro',\n",
    "            'Organicfood', 'charcoal', 'Kids toys', 'Fuel', 'Gaming hardware',\n",
    "            'Bike', 'allopathy', 'Solar']\n",
    "\n",
    "pred = np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create submission file\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission['File_Name'] = File_Name\n",
    "submission['Product'] = pred\n",
    "submission['Product'] = submission['Product'].apply(lambda x: classes[x])\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
